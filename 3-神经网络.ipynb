{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络\n",
    "> 在上个部分中，我们学习了如何在TensorFlow 2.0中构建模型。将应用这些相同的工具来构建、训练和进行神经网络的预测。我们将学习如何定义密集层、应用激活函数、选择优化器以及应用正则化来减少过拟合。同学们将利用TensorFlow的灵活性，同时使用低级别的线性代数和高级别的Keras API操作来定义和训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层的线性代数计算\n",
    "有两种方法可以在张量流中定义密集层。  \n",
    "- 涉及使用低级线性代数运算。  \n",
    "- 使用高级 keras 操作。  \n",
    "我们将使用第一种方法来构建下图所示的网络。\n",
    "\n",
    "<img src=\"../img/2_3_network.png\" alt=\"drawing\" style=\"width:600px;height:500px;\"/>\n",
    "\n",
    "输入层包含3个要素--‘教育’、‘婚姻状况’和‘年龄’，做为我们的输入`borrower_features`。隐藏层包含两个节点，输出层包含一个节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_features = np.array([[2.,2.,43.,]],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全连接层的形状是: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# 初始化 bias1\n",
    "bias1 = tf.Variable(1.0, tf.float32)\n",
    "# 将weights1初始化为3x2的全为1的变量\n",
    "weights1 = tf.Variable(tf.ones((3, 2)))\n",
    "\n",
    "# 执行borrower_features与weights1的矩阵乘法\n",
    "product1 = tf.matmul(borrower_features,weights1)\n",
    "\n",
    "## 对product1 + bias1应用sigmoid激活函数\n",
    "desen1 = tf.keras.activations.sigmoid(product1+bias1)\n",
    "\n",
    "# 打印dense1的形状\n",
    "print(\"全连接层的形状是: {}\".format(desen1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: 0.9525741338729858\n",
      "\n",
      " 实际值: 1\n"
     ]
    }
   ],
   "source": [
    "# 初始化权重2和偏置2\n",
    "\n",
    "bias2  =  tf.Variable(1.0, tf.float32)\n",
    "weights2= tf.Variable(tf.ones((2, 1)))\n",
    "# 执行矩阵乘法\n",
    "\n",
    "product2 =  tf.matmul(desen1,weights2)\n",
    "\n",
    "# 使用激活函数product2 + bias2\n",
    "prediction = tf.keras.activations.sigmoid(product2+bias2)\n",
    "print('预测值: {}'.format(prediction.numpy()[0, 0]))\n",
    "print('\\n 实际值: 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的模型在0到1之间生成了预测值。对于我们考虑的例子，实际值为1，而预测值是一个介于0和1之间的概率值。当然，由于我们还没有对模型的参数进行训练，这并没有什么意义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras来定义全连接层\n",
    "现在我们已经看到了如何使用线性代数在张量流中定义全连接层。下面，我们将跳过线性代数，让 keras 计算细节。这将允许我们构建下面的网络，它有 2 个隐藏层和 10 个特征，使用的代码比具有 1 个隐藏层和 3 个特征的网络所需的代码少。\n",
    "\n",
    "\n",
    "<img src=\"../img/2_4_network.png\" alt=\"drawing\" style=\"width:400px;\"/>\n",
    "\n",
    "\n",
    "为了构建这个网络，我们需要定义三个密集层，每个层都把前一层作为输入，乘以权重，并应用一个激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/uci_credit_card.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特定的列作为特征，并将其转换为 TensorFlow 张量\n",
    "features = df.columns[1:11].tolist()\n",
    "borrower_features = df[features].values\n",
    "borrower_features = tf.convert_to_tensor(borrower_features,np.float32)\n",
    "idx = tf.constant(list(range(0,100)))\n",
    "borrower_features=tf.gather(borrower_features,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dense1的形状:  (100, 7)\n",
      "\n",
      " dense2的形状:  (100, 3)\n",
      "\n",
      " 输出层的形状:  (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# 定义第一个全连接层\n",
    "dense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# 定义第二个全连接层\n",
    "dense2 = tf.keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "\n",
    "# 定义最后一个全连接层\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# 打印出各个层的形状\n",
    "print('\\n dense1的形状: ', dense1.shape)\n",
    "print('\\n dense2的形状: ', dense2.shape)\n",
    "print('\\n 输出层的形状: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本例中，我们仅用了 8 行代码就定义了两个稠密隐藏层和一个输出层。需要注意的是，每个层都有 100 行，因为输入数据包含了 100 个示例。简而言之，这段话强调了高级操作的简单性和效率，并且指出了每个层的行数等于示例数的事实。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数\n",
    "   - 隐藏层中的典型组件\n",
    "      -  线性：矩阵乘法\n",
    "      - 非线性：矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二分类问题\n",
    "我们再次使用之前的信用卡数据。目标变量`default`表示信用卡持有人在下一个期间是否违约。由于只有两种选项——**违约或未违约**——这是一个二分类问题。尽管数据集有很多特征，但我们只关注其中三个：最近三个信用卡账单的大小。最后，计算你经过训练的网络的预测输出`outputs`，并将其与目标变量 `default` 进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_amounts = df[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3']].to_numpy()\n",
    "default = df[['default.payment.next.month']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. ]\n",
      " [ 0. ]\n",
      " [-1. ]\n",
      " [-1. ]\n",
      " [-0.5]]\n"
     ]
    }
   ],
   "source": [
    "# 构建输入层\n",
    "inputs = tf.constant(bill_amounts,tf.float32)\n",
    "# 定义第一个隐藏层 3个节点\n",
    "dense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# 定义第二个隐藏层  2个节点\n",
    "dense2 = tf.keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "\n",
    "# 定义输出层\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# 打印前五个的误差\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果多次运行代码，大家会注意到每次错误都会有所变化。这是因为我们使用的是一个未经训练且参数随机初始化的模型。此外，错误落在-1到1之间的区间，是因为default是一个二元变量，取值为0和1，而outputs是一个介于0和1之间的概率值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多类别分类问题\n",
    "我们尝试一下从二分类问题过渡到多分类问题。多分类问题可以具有三个或更多值的目标。在信用卡数据集中，教育变量可以采用6个不同的值，以对应不同的教育级别。我们尝试以教育程度为目标，将我们的特征值从3列扩展到10列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[1:11].tolist()\n",
    "borrower_features = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14944354 0.21787906 0.17594026 0.16889884 0.150009   0.13782929]\n",
      " [0.14944354 0.21787906 0.17594026 0.16889884 0.150009   0.13782929]\n",
      " [0.14944354 0.21787906 0.17594026 0.16889884 0.150009   0.13782929]]\n"
     ]
    }
   ],
   "source": [
    "# 构建输入层\n",
    "inputs = tf.constant(borrower_features, tf.float32)\n",
    "\n",
    "# 定义第一个全连接神经网络，10个节点\n",
    "dense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# 定义第二个全连接神经网络\n",
    "dense2 = tf.keras.layers.Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# 定义输出层\n",
    "outputs = tf.keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "\n",
    "#答应结果\n",
    "print(outputs.numpy()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一行的`output`总和为1.与前面的练习一样，我们的预测尚无信息，因为我们使用的是具有随机初始化参数的未经训练的模型。这就是为什么模型倾向于为每个类分配相似的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "- 随机梯度下降优化器(SGD)\n",
    "    - 简单与易于解释\n",
    "- 均方根传播优化器(RMS)\n",
    "    - 每个特征应用不同的学习率\n",
    "    - 权重更新的过程中结合了动量的建立与衰减\n",
    "- Adam优化器\n",
    "    - 使用默认参数就会有很好的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部最小值\n",
    "下图绘制了一个损失函数，`loss_function`。图中，我们可以看到包含了一个“全局最小值”和一个“局部最小值”。\n",
    "\n",
    "<img src=\"../img/local_minima_dots.png\">\n",
    "\n",
    "\n",
    "使用`keras.optimizers.SGD()`来寻找`loss_function()`的全局最小值。我们将进行两次尝试，每次都使用不同的输入初始值来调用loss_function()。首先，我们将会将使用初始值为6.0的变量x_1；其次，我们将会将使用初始值为0.3的变量x_2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个上图的loss function\n",
    "import math\n",
    "def loss_function(x):\n",
    "    return 4.0 * math.cos(x - 1) + math.cos(2.0 * math.pi * x) / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.027515 0.25\n"
     ]
    }
   ],
   "source": [
    "# 初始化x_1和x_2\n",
    "x_1 = tf.Variable(6.0, tf.float32)\n",
    "x_2 = tf.Variable(0.3, tf.float32)\n",
    "\n",
    "#定义优化器\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for j in range(100):\n",
    "    # 使用x_1寻找loss_function的最小值\n",
    "    opt.minimize(lambda: loss_function(x_1),var_list=[x_1])\n",
    "    # 使用x_2寻找loss_function的最小值\n",
    "    opt.minimize(lambda: loss_function(x_2),var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用了相同的优化器和损失函数，但是使用了两个不同的初始值，得到了不同的最小值。使用x_2的时候，并没有找到全局的最小值，而只是找到了局部的最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 避免局部最小值\n",
    "我们可以看到损失函数很容易陷入到局部最小值设计的陷阱。解决这个问题的一种方法是使用**动量**，这使得优化器能够突破局部最小值。我们会再次使用上一个问题中定义好的并可用的损失函数`loss_function()`。\n",
    "在Tensorflow中，很多优化器都有动量，我们尝试使用RMSprop优化器。我们构建两个变量x_1与x_2 分别设置不同的动量，来比较一样它们之间不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.744511 0.24999999\n"
     ]
    }
   ],
   "source": [
    "# 初始化x_1和x_2\n",
    "x_1 = tf.Variable(0.05, tf.float32)\n",
    "x_2 = tf.Variable(0.05, tf.float32)\n",
    "\n",
    "# 构建2个优化器，分别为设置不同的动量\n",
    "opt_1 = tf.keras.optimizers.RMSprop(learning_rate=0.01,momentum=0.99)\n",
    "opt_2 = tf.keras.optimizers.RMSprop(learning_rate=0.01,momentum=0.00)\n",
    "\n",
    "for j in range(100):\n",
    "    opt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    \n",
    "    opt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "    \n",
    "\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全局最小值约为4.38。请注意，opt_1积累了动量，使得x_1更接近全局最小值。相反地，具有动量参数为0.0的opt_2在左侧的局部最小值处停滞不前。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化与dropout\n",
    "- 随机初始化\n",
    "    - 经常需要初始化成千上万的变量\n",
    "        - `tf.ones`可能没有很好的表现在寻找损失函数最小值方面\n",
    "        -  给每一个变量赋值过程过于繁琐\n",
    "    - 从分布中随机抽样初始值\n",
    "        - 正太分布\n",
    "        - 随机分布\n",
    "        - Glorot初始化\n",
    "- 对抗过度拟合\n",
    "    - dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow中的初始化\n",
    "好的初始化可以减少寻找全局最小值所需的时间。在这个练习中，我们将初始化神经网络的权重和偏置，用于预测信用卡违约决策。为了加深理解，我们将使用基本的线性代数方法而不是使用方便的Keras函数和高级操作。我们还将把输入特征的数量从3个扩展到23个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化layer1的权重\n",
    "w1= tf.Variable(tf.random.normal([23, 7]), tf.float32)\n",
    "#初始化layer1的偏置\n",
    "b1 = tf.Variable(tf.ones([7]), tf.float32)\n",
    "#初始化layer2的权重\n",
    "w2= tf.Variable(tf.random.normal([7, 1]), tf.float32)\n",
    "#初始化layer2的偏置\n",
    "b2 = tf.Variable(0.0, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型和损失函数\n",
    "将训练一个神经网络来预测信用卡持有人是否会违约。我们将使用的`borrower_features`和`default`作为训练网络的特征和目标。你已经在之前的练习中定义了权重和偏置。为了加深理解，我们将使用基本的线性代数方法而不是使用方便的Keras函数和高级操作。我们还将把输入特征的数量从3个扩展到23个。\n",
    "\n",
    "\n",
    "**注意**，预测层的定义为 $\\sigma(\\text{layer1} \\times w2 + b2)$,其中$\\sigma$是sigmoid 激活函数`layer1`是第一个隐藏密集层的节点的张量`w2`是权重的张量`b2`是偏置的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建测试集和训练集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:3000 ,1:24].astype(np.float32).to_numpy()\n",
    "y = df.iloc[:3000, 24].astype(np.float32).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_features, test_features, borrower_targets, test_targets = train_test_split(X, \n",
    "                                                                                    y, \n",
    "                                                                                    test_size=0.25,\n",
    "                                                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borrower_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def model(w1, b1, w2, b2, features=borrower_features):\n",
    "    #在layer1中使用激活函数relu\n",
    "    layer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n",
    "    #使用随机失活\n",
    "    dropout = tf.keras.layers.Dropout(0.25)(layer1)\n",
    "    return tf.keras.activations.sigmoid(tf.matmul(dropout, w2) + b2)\n",
    "    \n",
    "# 定义损失函数\n",
    "def loss_function(w1, b1, w2, b2, features=borrower_features, targets = borrower_targets):\n",
    "    targets = tf.reshape(targets, [-1, 1])\n",
    "    predictions = model(w1, b1, w2, b2)\n",
    "    \n",
    "    return tf.keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练神经网络\n",
    "在前面的练习中，我们定义了一个模型`model(w1, b1, w2, b2, features) `和一个损失函数` loss_function(w1, b1, w2, b2, features, targets)`。训练这个模型，并通过在测试集上预测违约结果来评估其性能，测试集包括 `test_features `和 `test_targets`，你可以使用它们。可训练的变量有`w1`、`b1`、`w2` 和 `b2`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "for j in range(1000):\n",
    "    #寻找损失函数的最小值\n",
    "    opt.minimize(lambda: loss_function(w1, b1, w2, b2), var_list=[w1, b1, w2, b2])\n",
    "    \n",
    "# 预测\n",
    "model_predictions = model(w1, b1, w2, b2, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion_matrix混淆矩阵是用来计算二分类模型在给定测试数据集上的混淆矩阵的函数。\n",
    "\n",
    "在二分类问题中，混淆矩阵是一种常见的评价指标。它是一个2x2的矩阵，表示预测结果和真实标签之间的对应关系。其中，行表示预测值（positive/negative），列表示真实值（positive/negative）。混淆矩阵的四个元素含义如下：\n",
    "\n",
    "- True Positive (TP)：预测结果为正例，且真实值也为正例的样本数  \n",
    "- False Positive (FP)：预测结果为正例，但真实值为负例的样本数  \n",
    "- False Negative (FN)：预测结果为负例，但真实值为正例的样本数  \n",
    "- True Negative (TN)：预测结果为负例，且真实值也为负例的样本数  \n",
    "\n",
    "**混淆矩阵可以帮助我们直观地了解模型的分类效果。** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[576,   7],\n",
       "       [161,   6]], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#构建混淆矩阵\n",
    "test_targets_binary = np.where(test_targets >= 0.5, 1, 0)\n",
    "model_predictions_binary = np.where(model_predictions >= 0.5, 1, 0)\n",
    "\n",
    "confusion_matrix(test_targets_binary.reshape(-1, 1), model_predictions_binary.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制混淆矩阵\n",
    "import seaborn as sns\n",
    "\n",
    "def confusion_matrix_plot(default,model_predictions):\n",
    "    df = pd.DataFrame(np.hstack([default, model_predictions.numpy() > 0.5]),\n",
    "                      columns = ['Actual','Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'], \n",
    "                                   rownames=['Actual'], colnames=['Predicted'])\n",
    "    \n",
    "    sns.heatmap(confusion_matrix,cmap=\"Greys\", fmt=\"d\", annot=True, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_plot(test_targets.reshape(-1, 1), model_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所示的图表称为“混淆矩阵”。对角元素显示正确预测的数量。非对角线元素显示错误预测的数量。我们可以看到该模型表现合理，但通过高估**0-不还款**实现。这表明我们可能需要训练更长时间，调整模型的超参数，或更改模型的架构。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
